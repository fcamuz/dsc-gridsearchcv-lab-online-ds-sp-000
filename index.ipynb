{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll explore how to use scikit-learn's `GridSearchCV` class to exhaustively search through every combination hyperparameters until we find the values for a given model.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Understand and explain parameter tuning and why it is necessary \n",
    "* Design and create a parameter grid for use with sklearn's GridSearchCV module\n",
    "* Use GridSearchCV to increase model performance through parameter tuning\n",
    "\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "For this lab, we'll be working with the [Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality) from the UCI Machine Learning Dataset Repository.  We'll be using data about the various features of wine to predict the quality of the wine on a scale from 1-10 stars, making this a multiclass classification problem.  \n",
    "\n",
    "### Getting Started\n",
    "\n",
    "Before we can begin GridSearching our way to optimal hyperparameters, we'll need to go through the basic steps of modeling.  This means that we'll need to:\n",
    "\n",
    "* Import and inspect the dataset (and clean, if necessary)\n",
    "* Split the data into training and testing sets\n",
    "* Build and fit a baseline model that we can compare against our GridSearch results.\n",
    "\n",
    "Run the cell below to import everything we'll need for this lab.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported all the necessary libraries and frameworks for this lab, we'll need to get the dataset.  \n",
    "\n",
    "Our data is stored in the file `winequality-red.csv`. Use pandas to import the data from this file and store it in a DataFrame.  Print the head to ensure that everything loaded correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's inspect our data a bit.  In the cell below, perform some basic Exploratory Data Analysis on our dataset.  Get a feel for your data by exploring the descriptive statistics and creating at least 1 visualization to help you better understand this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           float64\n",
       "volatile acidity        float64\n",
       "citric acid             float64\n",
       "residual sugar          float64\n",
       "chlorides               float64\n",
       "free sulfur dioxide     float64\n",
       "total sulfur dioxide    float64\n",
       "density                 float64\n",
       "pH                      float64\n",
       "sulphates               float64\n",
       "alcohol                 float64\n",
       "quality                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a25115e10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df.quality, df.pH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2530eac8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df.alcohol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1a2f1f11d0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f1f1240>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f1e7f98>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f1e7f60>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f214710>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f214a58>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f217dd8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f217eb8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f275550>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f275898>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f284c88>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f284fd0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f29d400>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f29d748>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec79b38>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec79e80>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec67ef0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec815f8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec839e8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec83d30>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb81eb8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb874a8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb7f898>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb7fbe0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1a2f20def0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f20dfd0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f1ef668>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f1ef9b0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f214da0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f214e80>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f27f4a8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f27f7f0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f275be0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f275f28>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f284f98>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f2766a0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f29da90>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f29ddd8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec79f60>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec67550>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec81940>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec81c88>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec83e10>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb81400>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb877f0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb87b38>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb7ff28>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb7fef0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1a2f1f18d0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f1e7c50>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f1effd0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f217a90>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f27ff28>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f284940>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f276dd8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec797f0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec67f28>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec836a0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb81dd8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb7f550>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1a2f1e75c0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f1efcf8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f217470>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f27fb38>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f275ef0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f2769e8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f29deb8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec67898>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec81fd0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb81748>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb87e80>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb845f8>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1a2f1e7908>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f1efdd8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f217748>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f27fe80>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f2845f8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2f276d30>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec794a8>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec67be0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2ec81f98>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb81a90>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb87f60>,\n",
       "  <matplotlib.lines.Line2D at 0x1a2eb84940>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([df[col] for col in df.columns])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Question:_** Based on your findings during your Exploratory Data Analysis, do you think that we need to do any sort of preprocessing on this dataset? Why or why not?\n",
    "\n",
    "Write your answer below this line:\n",
    "________________________________________________________________________________________________________________________________dataset includes only continues data that does not need to be preprossesed. there is no missing data. only the quality columns is categorical. that might need to be one_hot_encoded. but we do not want the target with multiple calues so it will stay like that. only column names need to change. there is space in between words.that might be problem in the model.  there are a few outliers but I wont delete them. \n",
    "\n",
    "\n",
    "### Preprocessing our Data\n",
    "\n",
    "Now, we'll perform any necessary preprocessing on our dataset before training our model.  We'll start by isolating the target variable that we are trying to predict.  \n",
    "\n",
    "In the cell below:\n",
    "* Store the data in the `quality` column inside the `y` variable\n",
    "* Drop the `quality` column from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=('fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',\n",
    "       'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol', 'quality')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.quality\n",
    "X = df.drop('quality', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Testing, and Cross Validation\n",
    "\n",
    "First we want to do a train test split to create a holdout set to evaluatate how good our final model will be. Remember that any time we make modeling decisions based on a section of our data and we risk overfitting to that data. We can make use of **_Cross Validation_** when using `GridSearchCV` to do model selectionn and hyperparameter tuning then test our final model choice on the test set.\n",
    "\n",
    "In the cell below:\n",
    "* Create a training and testing set using train_test_split (set ```random_state=42``` for reproducability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train,y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Baseline Model: Decision Trees\n",
    "\n",
    "In the cell below:\n",
    "* Create a `DecisionTreeClassifier` object.  \n",
    "* Get the `cross_val_score` for this model, with the `cv` parameter set to `3`.\n",
    "* Calculate and print the mean cross-validation score from our model.\n",
    "\n",
    "**_Note:_** If you need a refresher on how to use `cross_val_score`, check out the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score: 56.80%\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "dt_cv_score = cross_val_score(dt_clf,X_train, y_train, cv=3)\n",
    "mean_dt_cv_score = dt_cv_score.mean()\n",
    "\n",
    "print(f\"Mean Cross Validation Score: {mean_dt_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search: Decision Trees\n",
    "\n",
    "Take a second to interpret the results of our cross-validation score.  How well did our model do? How does this compare to a naive baseline level of accuracy (random guessing)?\n",
    "\n",
    "Write your answer below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "#it did pretty bad. 56 % is really low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating A Parameter Grid\n",
    "\n",
    "So far, our model has not have stellar performance. However, we've yet to modify the hyperparameters of the model.  Each dataset is different, and the chances that the best possible parameters for a given dataset also happen to be the default parameters set by by sklearn at instantiation is very low.  \n",
    "\n",
    "This means that we need to try **_Hyperparameter Tuning_**.  There are several strategies for searching for optimal hyperparameters--the one we'll be using, **_Combinatoric Grid Searching_**, is probably the most popular, because it performs an exhaustive search of all possible combinations.  \n",
    "\n",
    "The sklearn module we'll be using to accomplish this is `GridSearchCV`, which can be found inside of `sklearn.model_selection`.\n",
    "\n",
    "Take a minute to look at sklearn's user guide for [GridSearchCV](http://scikit-learn.org/stable/modules/grid_search.html#grid-search), and then complete the following task.\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Complete the `param_grid` dictionary.  In this dictionary, each key represents a parameter we want to tune, whereas the corresponding value is an array of every parameter value we'd like to check for that parameter.  For instance, if we would like try out the values `2`, `5`, and `10` for `min_samples_split`, our `param_grid` dictionary would include `\"min_samples_split\": [2, 5, 10]`.\n",
    "* Normally, you would have to just try different values to search through for each parameter.  However, in order to limit the complexity of this lab, the parameters and values to search through have been provided for you.  You just need to turn them into key-value pairs inside of the `param_grid` dictionary. Complete `param_grid` so that it tests the following values for each corresponding parameter:\n",
    "    * For `\"criterion\"`, try values of `\"gini\"` and `\"entropy\"`.\n",
    "    * For `\"max_depth\"`, try `None`, as well as `2, 3, 4, 5` and `6`.\n",
    "    * For `min_samples_split`, try `2, 5`, and `10`.\n",
    "    * For `\"min_samples_leaf\"`, try `1, 2, 3, 4, 5` and `6`.\n",
    "    \n",
    "    \n",
    "* Before you run the grid search take some time to understand what each of the specific hyperparameters mean. How does varying the values of each hyperparameter effect overfitting or underfitting of a decisionn tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid = {\"min_samples_split\": [2, 5, 10],\n",
    "                 \"criterion\": [\"gini\", \"entropy\"],\n",
    "                 \"max_depth\":[2, 3, 4, 5,6],\n",
    "                 \"min_samples_split\":[2,5,10],\n",
    "                 \n",
    "                 \"min_samples_leaf\":[1, 2, 3, 4, 5,6] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our parameter grid set up, we can create and use our `GridSearchCV` object.  Before we do, let's briefly think about the particulars of this model. \n",
    "\n",
    "Grid Searching works by training a model on the data for each unique combination of parameters, and then returning the parameters of the model that performed best. In order to protect us from randomness, it is common to implement K-Fold Cross Validation during this step.  For this lab, we'll set K = 3, meaning that we'll actually train 3 different models for each unique combination of parameters.  \n",
    "\n",
    "Given our `param_grid` and the knowledge that we're going to use Cross Validation with a value of 3, how many different Decision Trees will our `GridSearchCV` object have to train in order to try every possible combination and find the best parameter choices?\n",
    "\n",
    "Calculate and print your answer in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search will have to search through 1620 different permutations.\n"
     ]
    }
   ],
   "source": [
    "num_decision_trees = 3*2*5*3*6*3\n",
    "print(f\"Grid Search will have to search through {num_decision_trees} different permutations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of Decision Trees! Decision Trees are generally pretty quick to train, but that isn't the case with every type of model we could want to tune.  Be aware that if you set a particularly large search space of parameters inside your parameter grid, then Grid Searching could potentially take a very long time. \n",
    "\n",
    "Let's create our `GridSearchCV` object and fit it.  In the cell below:\n",
    "* Create a `GridSearchCV` object.  Pass in our model, the parameter grid, and `cv=3` to tell the object to use 3-Fold Cross Validation. Also pass in `return`\n",
    "* Call our grid search object's `fit()` method and pass in our data and labels, just as if we were using regular cross validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 3, 4, 5, 6],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid_search = GridSearchCV(dt_clf, dt_param_grid, cv=3)\n",
    "dt_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Best Parameters\n",
    "\n",
    "Now that we have fit our model using Grid Search, we need to inspect it to discover the optimal combination of parameters.\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Calculate the the mean training score.  An array of training score results can be found inside of the `.cv_results_` dictionary, with the key `mean_train_score`.\n",
    "* Calculate the testing score using the our grid search model's `.score()` method by passing in our data and labels. \n",
    "* Examine the appropriate attribute to discover the best estimator parameters found during the grid search. \n",
    "\n",
    "**_HINT:_** If you're unsure what attribute this is stored in, take a look at sklearn's [GridSearchCV Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00601244, 0.00474811, 0.00386794, 0.00305072, 0.00341312,\n",
       "        0.00379833, 0.00274889, 0.00287263, 0.00325926, 0.00276955,\n",
       "        0.00274356, 0.00312591, 0.00305645, 0.0027167 , 0.00345961,\n",
       "        0.0027945 , 0.00325624, 0.00403436, 0.0032684 , 0.0036602 ,\n",
       "        0.0035154 , 0.00362102, 0.00377409, 0.00543563, 0.00314864,\n",
       "        0.00315468, 0.00317009, 0.00325402, 0.00405431, 0.00345405,\n",
       "        0.00397476, 0.00395036, 0.00337251, 0.00319846, 0.00323725,\n",
       "        0.00314999, 0.00451231, 0.00440796, 0.00431681, 0.00369223,\n",
       "        0.003673  , 0.00360982, 0.00433111, 0.00368373, 0.00360926,\n",
       "        0.00361133, 0.00359297, 0.00480541, 0.00395234, 0.0046277 ,\n",
       "        0.00395171, 0.00358971, 0.00406623, 0.00392207, 0.00408069,\n",
       "        0.00406543, 0.00407163, 0.00407926, 0.00415333, 0.00409698,\n",
       "        0.00506035, 0.00466768, 0.00458924, 0.0046467 , 0.00468405,\n",
       "        0.00495132, 0.00419164, 0.00480604, 0.00480461, 0.00405439,\n",
       "        0.00406718, 0.00400011, 0.00453997, 0.00456436, 0.00447766,\n",
       "        0.00449665, 0.00467412, 0.00449157, 0.00550095, 0.00502149,\n",
       "        0.00504096, 0.00509469, 0.00453122, 0.00451438, 0.00439199,\n",
       "        0.00443514, 0.00500154, 0.0043749 , 0.00440375, 0.00505137,\n",
       "        0.00325569, 0.00381509, 0.00349196, 0.00364129, 0.00325688,\n",
       "        0.00323407, 0.00324265, 0.00368468, 0.0036703 , 0.00320339,\n",
       "        0.00321976, 0.00376074, 0.00334843, 0.00340915, 0.00327373,\n",
       "        0.00329272, 0.00321205, 0.00331807, 0.00414761, 0.00574732,\n",
       "        0.00414443, 0.00402443, 0.00398334, 0.00401537, 0.00398429,\n",
       "        0.00405908, 0.00412536, 0.00400392, 0.00403945, 0.0043141 ,\n",
       "        0.00445064, 0.00414467, 0.00452161, 0.00489696, 0.00464869,\n",
       "        0.00397031, 0.00490848, 0.00553838, 0.0051438 , 0.00487065,\n",
       "        0.00488528, 0.00484896, 0.00539772, 0.00514062, 0.00560792,\n",
       "        0.00715383, 0.00549714, 0.00548561, 0.00496213, 0.00530672,\n",
       "        0.00488639, 0.00475566, 0.00474421, 0.0047373 , 0.00626445,\n",
       "        0.00696866, 0.00583243, 0.00598947, 0.00576591, 0.00572165,\n",
       "        0.00691326, 0.0059433 , 0.00573969, 0.00562827, 0.00628352,\n",
       "        0.00589403, 0.00648896, 0.0071485 , 0.00555269, 0.00547727,\n",
       "        0.00547194, 0.00554148, 0.007502  , 0.00666992, 0.0066611 ,\n",
       "        0.0078663 , 0.00733153, 0.00739296, 0.00670934, 0.00707801,\n",
       "        0.00642967, 0.00634106, 0.00633589, 0.00638628, 0.00623099,\n",
       "        0.00639057, 0.00709176, 0.00615231, 0.00783594, 0.00732636]),\n",
       " 'std_fit_time': array([6.20511579e-04, 9.58640421e-04, 7.12197902e-04, 2.64866433e-04,\n",
       "        2.93637903e-04, 7.62195058e-04, 2.78758348e-05, 8.86524648e-05,\n",
       "        3.79285137e-04, 4.98993372e-05, 2.31534872e-05, 5.68626295e-04,\n",
       "        2.49498509e-04, 2.26094350e-05, 4.19186121e-04, 7.25218476e-05,\n",
       "        4.35609919e-04, 9.19869229e-04, 5.85113499e-05, 3.03318349e-04,\n",
       "        6.00910473e-05, 4.19579505e-04, 4.44133321e-04, 2.97371592e-03,\n",
       "        1.91065713e-06, 2.01914247e-05, 2.26655147e-05, 9.57672032e-05,\n",
       "        1.74518817e-04, 3.05070606e-04, 6.20029884e-04, 1.30718191e-04,\n",
       "        2.37984447e-04, 3.63905869e-05, 9.34955552e-05, 8.59850802e-06,\n",
       "        6.30914336e-04, 2.78139114e-04, 5.73304365e-04, 2.33612360e-05,\n",
       "        7.61948710e-05, 3.12260587e-05, 5.25861494e-04, 1.19326904e-04,\n",
       "        1.25863534e-05, 2.10034003e-05, 2.55816210e-05, 2.22720077e-04,\n",
       "        2.39776269e-04, 7.15007924e-04, 2.86858495e-04, 1.72326043e-05,\n",
       "        6.03147393e-04, 3.00725784e-04, 2.12948710e-05, 3.16922380e-05,\n",
       "        2.66107130e-05, 2.21154563e-05, 3.55983415e-05, 4.24590400e-05,\n",
       "        6.09988311e-04, 8.98112235e-05, 6.24726207e-04, 4.62064652e-04,\n",
       "        6.85217494e-04, 3.89369991e-04, 7.55018100e-05, 5.81548514e-04,\n",
       "        4.47260842e-04, 9.18932412e-05, 2.47251294e-05, 4.45812284e-05,\n",
       "        1.77468430e-05, 6.15515118e-05, 2.46778266e-05, 1.67508730e-05,\n",
       "        1.32277174e-04, 1.41291927e-05, 7.31323393e-04, 5.84605900e-04,\n",
       "        7.28413680e-04, 5.65230142e-04, 1.80307543e-04, 4.41284101e-05,\n",
       "        2.42276242e-05, 5.15625156e-05, 4.63872986e-04, 4.44049225e-05,\n",
       "        1.17769501e-04, 5.69460202e-04, 3.89984263e-06, 4.43274549e-04,\n",
       "        3.03867220e-04, 3.29470227e-04, 2.65672433e-05, 1.86163371e-05,\n",
       "        1.24683774e-05, 5.20642578e-04, 3.25326750e-04, 1.41144336e-05,\n",
       "        1.31747690e-05, 3.72910048e-04, 1.50500908e-04, 1.77233493e-04,\n",
       "        3.35558093e-05, 7.27186655e-05, 1.25818363e-05, 7.83153319e-05,\n",
       "        9.71409348e-05, 1.03081998e-03, 1.42641009e-04, 1.17727179e-05,\n",
       "        2.57935652e-05, 5.28484359e-05, 2.32498527e-05, 7.73963654e-05,\n",
       "        5.25646735e-05, 2.54124333e-05, 9.10166547e-05, 4.52669107e-04,\n",
       "        3.35752413e-04, 1.52235942e-04, 7.13568605e-04, 6.23725007e-04,\n",
       "        5.37794421e-04, 1.83982674e-05, 3.05736130e-05, 8.43145551e-04,\n",
       "        3.51073622e-04, 3.83021259e-05, 5.94557917e-05, 2.69831133e-05,\n",
       "        7.73040207e-04, 3.82814141e-04, 5.33150869e-04, 1.77282900e-03,\n",
       "        4.20953792e-04, 4.93593501e-04, 3.06762994e-04, 4.17082941e-04,\n",
       "        9.60510311e-05, 1.08811087e-05, 2.60755769e-05, 4.49604315e-05,\n",
       "        6.87081670e-04, 1.42428357e-03, 9.97946240e-05, 3.03552349e-04,\n",
       "        5.05653525e-05, 4.47521827e-05, 8.57158978e-04, 3.89894838e-04,\n",
       "        1.04221558e-04, 7.00140107e-05, 9.67525214e-04, 3.93937354e-04,\n",
       "        7.37670894e-04, 1.52927702e-03, 9.72625729e-06, 4.49932912e-05,\n",
       "        4.59366878e-05, 6.04180884e-05, 8.60627101e-04, 7.32909553e-05,\n",
       "        1.65928635e-04, 3.16424382e-04, 1.01429705e-03, 7.12569925e-04,\n",
       "        2.78546852e-04, 6.13827615e-04, 3.98056699e-05, 9.10485006e-05,\n",
       "        8.41817556e-05, 1.47755414e-05, 8.51668037e-05, 2.14325528e-04,\n",
       "        5.74777929e-04, 1.93117414e-05, 1.27915296e-03, 5.16990335e-04]),\n",
       " 'mean_score_time': array([0.00273927, 0.00219655, 0.00159883, 0.00132394, 0.00132211,\n",
       "        0.00118915, 0.00113209, 0.00123541, 0.00151626, 0.00114417,\n",
       "        0.00110976, 0.00121967, 0.00124025, 0.00111763, 0.00136344,\n",
       "        0.0011313 , 0.00153232, 0.00196123, 0.00117095, 0.00137981,\n",
       "        0.00121864, 0.00140564, 0.00120123, 0.00123374, 0.00113209,\n",
       "        0.00115514, 0.00112263, 0.00121236, 0.00147263, 0.00118899,\n",
       "        0.00138553, 0.00134691, 0.00115983, 0.00115299, 0.00116475,\n",
       "        0.00113734, 0.00144704, 0.00133499, 0.0013357 , 0.0011487 ,\n",
       "        0.00115466, 0.00115697, 0.00126831, 0.00114091, 0.00114202,\n",
       "        0.00114497, 0.00113002, 0.00175667, 0.00123636, 0.00134031,\n",
       "        0.00118272, 0.00115164, 0.00124733, 0.00124288, 0.00116698,\n",
       "        0.00116825, 0.00120536, 0.00112764, 0.00116205, 0.00117572,\n",
       "        0.00153343, 0.00140119, 0.00119869, 0.00144537, 0.00136137,\n",
       "        0.00144537, 0.0013214 , 0.00174212, 0.00134548, 0.00115442,\n",
       "        0.00114536, 0.0011696 , 0.00115236, 0.00116086, 0.00116301,\n",
       "        0.00115824, 0.00119567, 0.00115895, 0.00179195, 0.00164803,\n",
       "        0.00140015, 0.00127133, 0.00129175, 0.00125368, 0.00115275,\n",
       "        0.00119432, 0.00147947, 0.00118009, 0.00129493, 0.00150212,\n",
       "        0.00111826, 0.00143321, 0.00131965, 0.00127705, 0.00113503,\n",
       "        0.00114465, 0.00112931, 0.00143504, 0.00129906, 0.00112756,\n",
       "        0.00115108, 0.00143488, 0.00115021, 0.00131551, 0.00114171,\n",
       "        0.00112851, 0.00114663, 0.00114489, 0.00123787, 0.00147931,\n",
       "        0.00113853, 0.00115021, 0.00115093, 0.00113241, 0.0011483 ,\n",
       "        0.00113662, 0.00119305, 0.00114369, 0.00114743, 0.00131822,\n",
       "        0.00126243, 0.00117159, 0.00135104, 0.00126878, 0.00137528,\n",
       "        0.00112772, 0.00122889, 0.00127959, 0.00116229, 0.00113599,\n",
       "        0.00115108, 0.00113773, 0.00126266, 0.00119495, 0.0013907 ,\n",
       "        0.00219131, 0.00135159, 0.00128428, 0.00132895, 0.00129549,\n",
       "        0.0011793 , 0.00114806, 0.00116611, 0.00114115, 0.001302  ,\n",
       "        0.00117604, 0.00120687, 0.00123096, 0.00114727, 0.00115458,\n",
       "        0.00137575, 0.00121371, 0.00132489, 0.00118709, 0.00125885,\n",
       "        0.00122627, 0.00128555, 0.00138911, 0.00115077, 0.00115935,\n",
       "        0.00115204, 0.00117691, 0.00119138, 0.00116571, 0.00115561,\n",
       "        0.00136526, 0.00134913, 0.00128539, 0.00122531, 0.00138871,\n",
       "        0.00116841, 0.00116165, 0.0011607 , 0.00120417, 0.00125329,\n",
       "        0.00141064, 0.00136558, 0.00117334, 0.00155608, 0.00146492]),\n",
       " 'std_score_time': array([3.59153162e-04, 5.07130721e-04, 4.47290665e-04, 1.42670894e-04,\n",
       "        1.63423062e-04, 7.92301764e-05, 1.71234046e-05, 1.46060176e-04,\n",
       "        2.58779935e-04, 1.92839220e-05, 8.22534500e-06, 1.22187965e-04,\n",
       "        1.61195999e-04, 2.01519730e-05, 1.18594545e-04, 2.18834836e-05,\n",
       "        4.68296130e-04, 1.07595673e-03, 3.13997259e-05, 1.74263414e-04,\n",
       "        7.62644684e-05, 2.32141216e-04, 9.39053140e-05, 5.05613554e-05,\n",
       "        1.07426613e-05, 2.61964053e-05, 2.94800393e-06, 8.11984751e-05,\n",
       "        9.71766233e-05, 5.60789016e-05, 1.86274991e-04, 7.77008876e-05,\n",
       "        3.69481282e-05, 1.92839220e-05, 3.12636574e-05, 6.32995216e-06,\n",
       "        2.34106353e-04, 1.23134419e-04, 6.81383262e-05, 2.78307101e-05,\n",
       "        1.90565909e-05, 2.24884322e-05, 6.85865053e-05, 2.19503405e-05,\n",
       "        8.50990691e-06, 5.40298561e-06, 7.60534921e-06, 2.80267167e-04,\n",
       "        7.49806110e-05, 1.39880045e-04, 5.58698160e-05, 9.52945537e-06,\n",
       "        1.29217053e-04, 7.75040092e-05, 7.05744053e-06, 5.92059470e-06,\n",
       "        4.34943860e-05, 6.03889155e-06, 2.55727313e-05, 3.28477779e-05,\n",
       "        1.40723434e-04, 1.02825044e-04, 4.38674348e-05, 2.80286862e-04,\n",
       "        2.81422609e-04, 1.33034766e-04, 1.87903926e-04, 7.77290885e-04,\n",
       "        1.13571749e-04, 1.86586975e-05, 4.79610642e-06, 2.10604578e-05,\n",
       "        5.96946461e-06, 1.48293034e-05, 1.09896914e-05, 1.08176546e-05,\n",
       "        3.04006283e-05, 1.16816994e-05, 1.01169856e-04, 3.42816864e-04,\n",
       "        2.42403296e-04, 1.77714713e-04, 1.98779432e-04, 4.69494285e-05,\n",
       "        1.69707588e-06, 2.77538980e-05, 2.65070450e-04, 3.50582520e-06,\n",
       "        1.31007532e-04, 2.53812252e-04, 3.12884962e-06, 9.00573037e-05,\n",
       "        2.49250024e-04, 1.22420350e-04, 1.54713064e-05, 1.72003211e-05,\n",
       "        1.23692045e-05, 2.52972411e-04, 1.50265042e-04, 1.57913192e-05,\n",
       "        2.83353903e-05, 2.71613796e-04, 4.44057759e-05, 1.92589715e-04,\n",
       "        3.24695022e-05, 8.20458651e-06, 2.80985733e-05, 2.25957427e-05,\n",
       "        1.51427646e-04, 7.77542737e-05, 5.95993463e-06, 1.17453251e-05,\n",
       "        2.61829002e-05, 9.28983001e-06, 2.52140720e-05, 1.13047175e-05,\n",
       "        4.39574725e-05, 1.23380175e-05, 8.99975310e-06, 2.42401316e-04,\n",
       "        1.81400036e-04, 3.26108046e-05, 3.01394552e-04, 1.08406166e-04,\n",
       "        9.81868447e-05, 2.82771538e-06, 1.14815538e-04, 1.89882200e-04,\n",
       "        2.95042390e-05, 7.13753005e-06, 1.35374733e-05, 4.56121599e-06,\n",
       "        1.39064470e-04, 8.35982714e-05, 1.57971456e-04, 7.05302471e-04,\n",
       "        1.85861313e-04, 1.16369978e-04, 2.66537114e-04, 1.05274575e-04,\n",
       "        5.54117925e-05, 1.22537769e-05, 1.71008901e-05, 2.75531385e-06,\n",
       "        1.68809222e-04, 2.48110653e-05, 3.39325845e-05, 1.03347785e-04,\n",
       "        2.05095417e-06, 8.18840464e-06, 8.03137637e-05, 8.90025068e-06,\n",
       "        2.47591084e-04, 5.65291742e-05, 1.44140677e-04, 6.99701551e-05,\n",
       "        1.58861933e-04, 3.15194672e-04, 1.56636148e-05, 1.75766227e-05,\n",
       "        5.19073988e-06, 7.60534921e-06, 3.70421968e-05, 2.00094922e-05,\n",
       "        6.63300883e-06, 1.29353060e-04, 1.77432588e-04, 1.58947587e-04,\n",
       "        9.04128045e-05, 2.44085386e-04, 1.03491851e-05, 1.56853737e-05,\n",
       "        4.60805544e-06, 6.05803214e-05, 1.27202413e-04, 2.63397492e-04,\n",
       "        7.51060993e-05, 1.31661370e-05, 2.98992890e-04, 2.21355213e-04]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
       "                    1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
       "                    1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
       "                    1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
       "                    1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
       "                    1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
       "                    1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
       "                    1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
       "                    1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
       "                    1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
       "                    10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10,\n",
       "                    2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
       "                    10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10,\n",
       "                    2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
       "                    10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10,\n",
       "                    2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
       "                    10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10,\n",
       "                    2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
       "                    10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10,\n",
       "                    2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_samples_split': 10}],\n",
       " 'split0_test_score': array([0.51364764, 0.51364764, 0.51364764, 0.51364764, 0.51364764,\n",
       "        0.51364764, 0.51364764, 0.51364764, 0.51364764, 0.51364764,\n",
       "        0.51364764, 0.51364764, 0.51364764, 0.51364764, 0.51364764,\n",
       "        0.51364764, 0.51364764, 0.51364764, 0.52853598, 0.52853598,\n",
       "        0.52853598, 0.52853598, 0.52853598, 0.52853598, 0.52853598,\n",
       "        0.52853598, 0.52853598, 0.52853598, 0.52853598, 0.52853598,\n",
       "        0.52853598, 0.52853598, 0.52853598, 0.52853598, 0.52853598,\n",
       "        0.52853598, 0.53349876, 0.53349876, 0.53349876, 0.53598015,\n",
       "        0.53349876, 0.53349876, 0.53349876, 0.53349876, 0.53349876,\n",
       "        0.53349876, 0.53349876, 0.53349876, 0.53101737, 0.53101737,\n",
       "        0.53101737, 0.53101737, 0.53101737, 0.53101737, 0.54590571,\n",
       "        0.54342432, 0.54342432, 0.54342432, 0.54094293, 0.54094293,\n",
       "        0.54590571, 0.54590571, 0.54590571, 0.54590571, 0.54590571,\n",
       "        0.54590571, 0.54590571, 0.54590571, 0.54590571, 0.54342432,\n",
       "        0.54342432, 0.54342432, 0.53101737, 0.52605459, 0.52853598,\n",
       "        0.53101737, 0.52853598, 0.52853598, 0.53349876, 0.53349876,\n",
       "        0.53101737, 0.54342432, 0.54342432, 0.54094293, 0.54094293,\n",
       "        0.53846154, 0.53846154, 0.53846154, 0.53846154, 0.53349876,\n",
       "        0.51116625, 0.51116625, 0.51116625, 0.51116625, 0.51116625,\n",
       "        0.51116625, 0.51116625, 0.51116625, 0.51116625, 0.51116625,\n",
       "        0.51116625, 0.51116625, 0.51116625, 0.51116625, 0.51116625,\n",
       "        0.51116625, 0.51116625, 0.51116625, 0.53598015, 0.53598015,\n",
       "        0.53598015, 0.53598015, 0.53598015, 0.53598015, 0.53598015,\n",
       "        0.53598015, 0.53598015, 0.53598015, 0.53598015, 0.53598015,\n",
       "        0.53598015, 0.53598015, 0.53598015, 0.53598015, 0.53598015,\n",
       "        0.53598015, 0.5235732 , 0.5235732 , 0.5235732 , 0.5235732 ,\n",
       "        0.5235732 , 0.5235732 , 0.5235732 , 0.5235732 , 0.5235732 ,\n",
       "        0.5235732 , 0.5235732 , 0.5235732 , 0.5235732 , 0.5235732 ,\n",
       "        0.5235732 , 0.5235732 , 0.5235732 , 0.5235732 , 0.51364764,\n",
       "        0.51364764, 0.51116625, 0.51364764, 0.51364764, 0.51116625,\n",
       "        0.51116625, 0.51116625, 0.51116625, 0.51116625, 0.51116625,\n",
       "        0.51116625, 0.51116625, 0.51116625, 0.51116625, 0.51612903,\n",
       "        0.51612903, 0.51364764, 0.53846154, 0.53101737, 0.53349876,\n",
       "        0.53598015, 0.53598015, 0.52853598, 0.53846154, 0.53598015,\n",
       "        0.53101737, 0.53101737, 0.53846154, 0.53349876, 0.51861042,\n",
       "        0.52109181, 0.52109181, 0.52605459, 0.52605459, 0.52853598]),\n",
       " 'split1_test_score': array([0.55778894, 0.55778894, 0.55778894, 0.55778894, 0.55778894,\n",
       "        0.55778894, 0.55778894, 0.55778894, 0.55778894, 0.55778894,\n",
       "        0.55778894, 0.55778894, 0.55778894, 0.55778894, 0.55778894,\n",
       "        0.55778894, 0.55778894, 0.55778894, 0.57286432, 0.57286432,\n",
       "        0.57286432, 0.57286432, 0.57286432, 0.57286432, 0.57286432,\n",
       "        0.57286432, 0.57286432, 0.57286432, 0.57286432, 0.57286432,\n",
       "        0.57286432, 0.57286432, 0.57286432, 0.57286432, 0.57286432,\n",
       "        0.57286432, 0.60050251, 0.60301508, 0.60301508, 0.60301508,\n",
       "        0.60301508, 0.60301508, 0.60301508, 0.60050251, 0.60301508,\n",
       "        0.60301508, 0.60301508, 0.60301508, 0.60301508, 0.60301508,\n",
       "        0.60301508, 0.60301508, 0.60301508, 0.60301508, 0.58040201,\n",
       "        0.58040201, 0.59296482, 0.57788945, 0.58040201, 0.59296482,\n",
       "        0.59045226, 0.58040201, 0.58291457, 0.58291457, 0.58291457,\n",
       "        0.58291457, 0.58291457, 0.58291457, 0.59296482, 0.59045226,\n",
       "        0.59045226, 0.60050251, 0.59296482, 0.59547739, 0.58040201,\n",
       "        0.60301508, 0.59296482, 0.59045226, 0.59547739, 0.59547739,\n",
       "        0.59547739, 0.59296482, 0.59296482, 0.5879397 , 0.60301508,\n",
       "        0.60050251, 0.59045226, 0.61055276, 0.61055276, 0.61306533,\n",
       "        0.5678392 , 0.5678392 , 0.5678392 , 0.5678392 , 0.5678392 ,\n",
       "        0.5678392 , 0.5678392 , 0.5678392 , 0.5678392 , 0.5678392 ,\n",
       "        0.5678392 , 0.5678392 , 0.5678392 , 0.5678392 , 0.5678392 ,\n",
       "        0.5678392 , 0.5678392 , 0.5678392 , 0.59296482, 0.59296482,\n",
       "        0.59296482, 0.59296482, 0.59296482, 0.59296482, 0.59296482,\n",
       "        0.59296482, 0.59296482, 0.59296482, 0.59296482, 0.59296482,\n",
       "        0.59296482, 0.59296482, 0.59296482, 0.59296482, 0.59296482,\n",
       "        0.59296482, 0.60552764, 0.60552764, 0.60552764, 0.60552764,\n",
       "        0.60552764, 0.60552764, 0.60552764, 0.60552764, 0.60552764,\n",
       "        0.60552764, 0.60552764, 0.60552764, 0.6080402 , 0.6080402 ,\n",
       "        0.6080402 , 0.6080402 , 0.6080402 , 0.6080402 , 0.59045226,\n",
       "        0.59296482, 0.59547739, 0.59296482, 0.59296482, 0.59547739,\n",
       "        0.59296482, 0.59296482, 0.59547739, 0.59547739, 0.59547739,\n",
       "        0.59547739, 0.60301508, 0.60301508, 0.60301508, 0.59296482,\n",
       "        0.59296482, 0.59296482, 0.58542714, 0.58542714, 0.5879397 ,\n",
       "        0.58542714, 0.58542714, 0.5879397 , 0.5678392 , 0.5678392 ,\n",
       "        0.57286432, 0.5678392 , 0.5678392 , 0.5678392 , 0.57286432,\n",
       "        0.57286432, 0.57286432, 0.56532663, 0.56532663, 0.56532663]),\n",
       " 'split2_test_score': array([0.57537688, 0.57537688, 0.57537688, 0.57537688, 0.57537688,\n",
       "        0.57537688, 0.57537688, 0.57537688, 0.57537688, 0.57537688,\n",
       "        0.57537688, 0.57537688, 0.57537688, 0.57537688, 0.57537688,\n",
       "        0.57537688, 0.57537688, 0.57537688, 0.55527638, 0.55527638,\n",
       "        0.55527638, 0.55527638, 0.55527638, 0.55527638, 0.55527638,\n",
       "        0.55527638, 0.55527638, 0.55527638, 0.55527638, 0.55527638,\n",
       "        0.55527638, 0.55527638, 0.55527638, 0.55527638, 0.55527638,\n",
       "        0.55527638, 0.5678392 , 0.5678392 , 0.5678392 , 0.57035176,\n",
       "        0.57035176, 0.5678392 , 0.56030151, 0.56030151, 0.56030151,\n",
       "        0.56030151, 0.56030151, 0.56030151, 0.56532663, 0.56532663,\n",
       "        0.56532663, 0.56532663, 0.56532663, 0.56532663, 0.56532663,\n",
       "        0.56532663, 0.56281407, 0.56532663, 0.56532663, 0.56281407,\n",
       "        0.57035176, 0.57035176, 0.56532663, 0.57788945, 0.57788945,\n",
       "        0.57286432, 0.57537688, 0.57537688, 0.57537688, 0.56532663,\n",
       "        0.56532663, 0.56532663, 0.58291457, 0.58040201, 0.57537688,\n",
       "        0.57286432, 0.57286432, 0.57035176, 0.5678392 , 0.5678392 ,\n",
       "        0.56281407, 0.56532663, 0.56532663, 0.56030151, 0.55778894,\n",
       "        0.55778894, 0.55778894, 0.57286432, 0.5678392 , 0.5678392 ,\n",
       "        0.58040201, 0.58040201, 0.58040201, 0.58040201, 0.58040201,\n",
       "        0.58040201, 0.58040201, 0.58040201, 0.58040201, 0.58040201,\n",
       "        0.58040201, 0.58040201, 0.58040201, 0.58040201, 0.58040201,\n",
       "        0.58040201, 0.58040201, 0.58040201, 0.60050251, 0.60050251,\n",
       "        0.60050251, 0.60050251, 0.60050251, 0.60050251, 0.60050251,\n",
       "        0.60050251, 0.60050251, 0.60050251, 0.60050251, 0.60050251,\n",
       "        0.60050251, 0.60050251, 0.60050251, 0.60050251, 0.60050251,\n",
       "        0.60050251, 0.61809045, 0.61809045, 0.61557789, 0.61809045,\n",
       "        0.61809045, 0.61557789, 0.61809045, 0.61809045, 0.61557789,\n",
       "        0.61557789, 0.61557789, 0.61557789, 0.61557789, 0.61557789,\n",
       "        0.61557789, 0.61809045, 0.61809045, 0.61809045, 0.62060302,\n",
       "        0.62562814, 0.61809045, 0.62060302, 0.62060302, 0.61306533,\n",
       "        0.61809045, 0.61809045, 0.61557789, 0.61557789, 0.61557789,\n",
       "        0.61557789, 0.6080402 , 0.6080402 , 0.6080402 , 0.61055276,\n",
       "        0.61055276, 0.61055276, 0.57286432, 0.58291457, 0.57537688,\n",
       "        0.57286432, 0.57035176, 0.57286432, 0.57286432, 0.57537688,\n",
       "        0.57286432, 0.57035176, 0.57286432, 0.57286432, 0.57537688,\n",
       "        0.57537688, 0.57537688, 0.5678392 , 0.5678392 , 0.5678392 ]),\n",
       " 'mean_test_score': array([0.54879066, 0.54879066, 0.54879066, 0.54879066, 0.54879066,\n",
       "        0.54879066, 0.54879066, 0.54879066, 0.54879066, 0.54879066,\n",
       "        0.54879066, 0.54879066, 0.54879066, 0.54879066, 0.54879066,\n",
       "        0.54879066, 0.54879066, 0.54879066, 0.55212677, 0.55212677,\n",
       "        0.55212677, 0.55212677, 0.55212677, 0.55212677, 0.55212677,\n",
       "        0.55212677, 0.55212677, 0.55212677, 0.55212677, 0.55212677,\n",
       "        0.55212677, 0.55212677, 0.55212677, 0.55212677, 0.55212677,\n",
       "        0.55212677, 0.56713928, 0.56797331, 0.56797331, 0.56964137,\n",
       "        0.56880734, 0.56797331, 0.56547123, 0.5646372 , 0.56547123,\n",
       "        0.56547123, 0.56547123, 0.56547123, 0.56630525, 0.56630525,\n",
       "        0.56630525, 0.56630525, 0.56630525, 0.56630525, 0.56380317,\n",
       "        0.56296914, 0.56630525, 0.56213511, 0.56213511, 0.56547123,\n",
       "        0.56880734, 0.56547123, 0.5646372 , 0.56880734, 0.56880734,\n",
       "        0.56713928, 0.56797331, 0.56797331, 0.57130942, 0.56630525,\n",
       "        0.56630525, 0.56964137, 0.56880734, 0.56713928, 0.56130108,\n",
       "        0.56880734, 0.5646372 , 0.56296914, 0.56547123, 0.56547123,\n",
       "        0.56296914, 0.56713928, 0.56713928, 0.56296914, 0.56713928,\n",
       "        0.56547123, 0.56213511, 0.57381151, 0.57214345, 0.57130942,\n",
       "        0.5529608 , 0.5529608 , 0.5529608 , 0.5529608 , 0.5529608 ,\n",
       "        0.5529608 , 0.5529608 , 0.5529608 , 0.5529608 , 0.5529608 ,\n",
       "        0.5529608 , 0.5529608 , 0.5529608 , 0.5529608 , 0.5529608 ,\n",
       "        0.5529608 , 0.5529608 , 0.5529608 , 0.57631359, 0.57631359,\n",
       "        0.57631359, 0.57631359, 0.57631359, 0.57631359, 0.57631359,\n",
       "        0.57631359, 0.57631359, 0.57631359, 0.57631359, 0.57631359,\n",
       "        0.57631359, 0.57631359, 0.57631359, 0.57631359, 0.57631359,\n",
       "        0.57631359, 0.58215179, 0.58215179, 0.58131776, 0.58215179,\n",
       "        0.58215179, 0.58131776, 0.58215179, 0.58215179, 0.58131776,\n",
       "        0.58131776, 0.58131776, 0.58131776, 0.58215179, 0.58215179,\n",
       "        0.58215179, 0.58298582, 0.58298582, 0.58298582, 0.57464554,\n",
       "        0.57714762, 0.57464554, 0.57547957, 0.57547957, 0.57297748,\n",
       "        0.57381151, 0.57381151, 0.57381151, 0.57381151, 0.57381151,\n",
       "        0.57381151, 0.57381151, 0.57381151, 0.57381151, 0.57297748,\n",
       "        0.57297748, 0.57214345, 0.56547123, 0.56630525, 0.56547123,\n",
       "        0.5646372 , 0.56380317, 0.56296914, 0.55963303, 0.55963303,\n",
       "        0.558799  , 0.55629691, 0.55963303, 0.55796497, 0.55546289,\n",
       "        0.55629691, 0.55629691, 0.5529608 , 0.5529608 , 0.55379483]),\n",
       " 'std_test_score': array([0.02601181, 0.02601181, 0.02601181, 0.02601181, 0.02601181,\n",
       "        0.02601181, 0.02601181, 0.02601181, 0.02601181, 0.02601181,\n",
       "        0.02601181, 0.02601181, 0.02601181, 0.02601181, 0.02601181,\n",
       "        0.02601181, 0.02601181, 0.02601181, 0.01825101, 0.01825101,\n",
       "        0.01825101, 0.01825101, 0.01825101, 0.01825101, 0.01825101,\n",
       "        0.01825101, 0.01825101, 0.01825101, 0.01825101, 0.01825101,\n",
       "        0.01825101, 0.01825101, 0.01825101, 0.01825101, 0.01825101,\n",
       "        0.01825101, 0.02738658, 0.02840909, 0.02840909, 0.02739945,\n",
       "        0.02842979, 0.02840909, 0.0286417 , 0.02755217, 0.0286417 ,\n",
       "        0.0286417 , 0.0286417 , 0.0286417 , 0.02943108, 0.02943108,\n",
       "        0.02943108, 0.02943108, 0.02943108, 0.02943108, 0.0141383 ,\n",
       "        0.01520261, 0.02039453, 0.01426325, 0.01628175, 0.02134191,\n",
       "        0.01823717, 0.01451116, 0.01513206, 0.0164234 , 0.0164234 ,\n",
       "        0.0156534 , 0.01599933, 0.01599933, 0.019444  , 0.01923108,\n",
       "        0.01923108, 0.02352335, 0.02719882, 0.02987137, 0.02340322,\n",
       "        0.02956164, 0.02696095, 0.02583266, 0.02538348, 0.02538348,\n",
       "        0.02634283, 0.02028579, 0.02028579, 0.0192978 , 0.02620904,\n",
       "        0.02592587, 0.02146656, 0.02946878, 0.02961703, 0.03260801,\n",
       "        0.03017547, 0.03017547, 0.03017547, 0.03017547, 0.03017547,\n",
       "        0.03017547, 0.03017547, 0.03017547, 0.03017547, 0.03017547,\n",
       "        0.03017547, 0.03017547, 0.03017547, 0.03017547, 0.03017547,\n",
       "        0.03017547, 0.03017547, 0.03017547, 0.02886247, 0.02886247,\n",
       "        0.02886247, 0.02886247, 0.02886247, 0.02886247, 0.02886247,\n",
       "        0.02886247, 0.02886247, 0.02886247, 0.02886247, 0.02886247,\n",
       "        0.02886247, 0.02886247, 0.02886247, 0.02886247, 0.02886247,\n",
       "        0.02886247, 0.04199374, 0.04199374, 0.04129076, 0.04199374,\n",
       "        0.04199374, 0.04129076, 0.04199374, 0.04199374, 0.04129076,\n",
       "        0.04129076, 0.04129076, 0.04129076, 0.04179366, 0.04179366,\n",
       "        0.04179366, 0.04247195, 0.04247195, 0.04247195, 0.04510679,\n",
       "        0.04710123, 0.04609763, 0.04541353, 0.04541353, 0.04456068,\n",
       "        0.04573448, 0.04573448, 0.04532022, 0.04532022, 0.04532022,\n",
       "        0.04532022, 0.04462125, 0.04462125, 0.04462125, 0.04107936,\n",
       "        0.04107936, 0.04223404, 0.01988815, 0.02512941, 0.02331812,\n",
       "        0.02102299, 0.02072782, 0.02525844, 0.01520272, 0.0171077 ,\n",
       "        0.01976759, 0.01801637, 0.01520272, 0.01752852, 0.02624177,\n",
       "        0.02507055, 0.02507055, 0.01917204, 0.01917204, 0.01800167]),\n",
       " 'rank_test_score': array([163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163,\n",
       "        163, 163, 163, 163, 163, 145, 145, 145, 145, 145, 145, 145, 145,\n",
       "        145, 145, 145, 145, 145, 145, 145, 145, 145, 145,  72,  67,  67,\n",
       "         59,  61,  67,  88, 100,  88,  88,  88,  88,  78,  78,  78,  78,\n",
       "         78,  78, 104, 106,  78, 111, 111,  88,  61,  88, 100,  61,  61,\n",
       "         72,  67,  67,  57,  78,  78,  59,  61,  72, 114,  61, 100, 106,\n",
       "         88,  88, 106,  72,  72, 106,  72,  88, 111,  42,  55,  57, 125,\n",
       "        125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,\n",
       "        125, 125, 125, 125,  20,  20,  20,  20,  20,  20,  20,  20,  20,\n",
       "         20,  20,  20,  20,  20,  20,  20,  20,  20,   4,   4,  13,   4,\n",
       "          4,  13,   4,   4,  13,  13,  13,  13,   4,   4,   4,   1,   1,\n",
       "          1,  40,  19,  40,  38,  38,  52,  42,  42,  42,  42,  42,  42,\n",
       "         42,  42,  42,  52,  52,  55,  88,  78,  88, 100, 104, 106, 115,\n",
       "        115, 118, 120, 115, 119, 123, 120, 120, 125, 125, 124], dtype=int32)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_gs_training_score =dt_grid_search.cv_results_\n",
    "dt_gs_testing_score = dt_grid_search.score(X_test, y_test)\n",
    "dt_gs_training_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Testing Score: 56.25%\n",
      "Best Parameter Combination Found During Grid Search:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 4,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(f\"Mean Training Score: {dt_gs_training_score :.2%}\")\n",
    "print(f\"Mean Testing Score: {dt_gs_testing_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "dt_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Question:_** What effect, if any, did our parameter tuning have on model performance? Will GridSearchCV always discover a perfectly (global) optimal set of parameters? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "\n",
    "\n",
    "#it did not imprived the score much, but made the model smaller ,it hopefully will prevent overfitting. . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning More Advanced Models: Random Forests\n",
    "\n",
    "Now that we have some experience with Grid Searching through parameter values for a Decision Tree Classifier, let's try our luck with a more advanced model and tune a _Random Forest Classifier_.  \n",
    "\n",
    "We'll start by repeating the same process we did for our Decision Tree Classifier, except with a Random Forest Classifier instead. \n",
    "\n",
    "In the cell below:\n",
    "* Create a `RandomForestClassifier` object.\n",
    "* Use Cross Validation with `cv=3` to generate a baseline score for this model type, so that we have something to compare our tuned model performance to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score for Random Forest Classifier: 61.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "mean_rf_cv_score = cross_val_score(rf_clf, X_train, y_train, cv=3).mean()\n",
    "\n",
    "print(f\"Mean Cross Validation Score for Random Forest Classifier: {mean_rf_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our baseline score, we'll create a parameter grid specific to our Random Forest Classifier.  \n",
    "\n",
    "Again--in a real world situation, you will need to decide what parameters to tune, and be very thoughtful about what values to test for each parameter.  However, since this is a lab, we have provided the following table in the interest of simplicity.  Complete the `rf_param_grid` dictionary with the following key value pairs:\n",
    " \n",
    " \n",
    " |     Parameter     |         Values         |\n",
    "|:-----------------:|:----------------------:|\n",
    "|    n_estimators   |      [10, 30, 100]     |\n",
    "|     criterion     |   ['gini', 'entropy']  |\n",
    "|     max_depth     | [None, 2, 6, 10] |\n",
    "| min_samples_split |       [5, 10]       |\n",
    "|  min_samples_leaf |   [3, 6]   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\"n_estimators\":[10, 30, 100],\n",
    "                 \"criterion\":['gini', 'entropy'],\n",
    "                 \"max_depth\":[None, 2, 6, 10],\n",
    "                 \"min_samples_split\":[5, 10],\n",
    "                 \"min_samples_leaf\":[3, 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we have our parameter grid, we can grid search through it with our Random Forest. \n",
    "\n",
    "In the cell below, follow the process we used with Decision Trees above to grid search for the best parameters for our Random Forest Classifier.  \n",
    "\n",
    "When creating your `GridSearchCV` object,  pass in:\n",
    "* our Random Forest Classifier\n",
    "* The parameter grid for our Random Forest Classifier\n",
    "* `cv=3` \n",
    "* **_Do not_** pass in `return_train_score` as we did with our Decision Trees example above.  In the interest of runtime, we'll only worry about testing accuracy this time. \n",
    "\n",
    "\n",
    "**_NOTE:_** The runtime on the following cell will be over a minute on most computers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 64.30%\n",
      "Total Runtime for Grid Search on Random Forest Classifier: 37.83 seconds\n",
      "\n",
      "Optimal Parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rf_grid_search = GridSearchCV(rf_clf , rf_param_grid , cv=3)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Testing Accuracy: {rf_grid_search.best_score_ :.2%}\")\n",
    "print(f\"Total Runtime for Grid Search on Random Forest Classifier: {time.time() - start :.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Optimal Parameters: {rf_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Our Results\n",
    "Did tuning the hyperparameters of our Random Forest Classifier improve model performance? Is this performance increase significant? Which model did better? If you had to choose, which model would you put into production? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "#the accuracy improve a little bit. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Gradient Boosted Trees (AdaBoost)\n",
    "\n",
    "The last model we'll tune in this lab is an AdaBoost Classifier, although tuning this model will generally be similar to tuning other forms of Gradient Boosted Tree (GBT) models.  \n",
    "\n",
    "In the cell below, create an AdaBoost Classifier Object.  Then, as we did with the previous two examples, fit the model using using Cross Validation to get a baseline testing accuracy so we can see how an untuned AdaBoost model performs on this task.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score for AdaBoost: 54.22%\n"
     ]
    }
   ],
   "source": [
    "adaboost_clf = AdaBoostClassifier()\n",
    "adaboost_mean_cv_score = np.mean(cross_val_score(adaboost_clf, X_train, y_train, cv=3))\n",
    "\n",
    "print(f\"Mean Cross Validation Score for AdaBoost: {adaboost_mean_cv_score :.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now, onto creating the parameter grid for AdaBoost.  \n",
    "\n",
    "Complete the `adaboost_param_grid` dictionary by adding in the following key-value pairs:\n",
    "\n",
    "|   Parameters  |      Values     |\n",
    "|:-------------:|:---------------:|\n",
    "|  n_estimators |  [50, 100, 250] |\n",
    "| learning_rate | [1.0, 0.5, 0.1] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_param_grid = {\n",
    "    'n_estimators': [50, 100, 250],\n",
    "    'learning_rate': [1.0, 0.5, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great.  Now, for the finale--use Grid Search to find optimal parameters for AdaBoost, and see how the model performs overall!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 56.30%\n",
      "Total Runtime for Grid Search on AdaBoost: 290.00 seconds\n",
      "\n",
      "Optimal Parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "adaboost_grid_search = GridSearchCV(adaboost_clf , adaboost_param_grid , cv=3)\n",
    "adaboost_grid_search .fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"Testing Accuracy: {adaboost_grid_search.best_score_ :.2%}\")\n",
    "print(f\"Total Runtime for Grid Search on AdaBoost: {time.time() - start :.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Optimal Parameters: {adaboost_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Best Performing Model on the Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The holdout accuracy for the decision tree is 63.75%\n"
     ]
    }
   ],
   "source": [
    "holdout_accuracy = rf_grid_search.score(X_test, y_test)\n",
    "\n",
    "print(f'The holdout accuracy for the decision tree is {holdout_accuracy :.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we learned:\n",
    "\n",
    "* How to iteratively search for optimal model parameters using `GridSearhCV`\n",
    "* How to tune model parameters for Decision Trees, Random Forests, and AdaBoost models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
